{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "data['Year'] = data['Date'].dt.year\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "\n",
    "data.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "data_cleaned = data.dropna(subset=['Task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category0 = data[data['Task'] == 0]\n",
    "category1 = data[data['Task'] == 1]\n",
    "\n",
    "diff = len(category0) - len(category1)\n",
    "class_0_size = len(category0)\n",
    "class_1_size = len(category1)\n",
    "diff\n",
    "\n",
    "num_rows_to_drop = int((class_0_size - len(data)/2) )\n",
    "\n",
    "rows_to_drop = category0.sample(n=num_rows_to_drop, random_state=42)\n",
    "\n",
    "category0 = category0.drop(rows_to_drop.index)\n",
    "\n",
    "category0.reset_index(drop=True, inplace=True)\n",
    "category0['Task'].value_counts()\n",
    "\n",
    "diff = len(category0) - len(category1)\n",
    "class_0_size = len(category0)\n",
    "class_1_size = len(category1)\n",
    "diff\n",
    "\n",
    "category1_oversampled = category1.sample(n=class_0_size, replace=True,random_state=42)\n",
    "\n",
    "data = pd.concat([category0, category1_oversampled])\n",
    "data['Task'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data_cleaned = data\n",
    "\n",
    "X = data_cleaned.drop('Task', axis=1)\n",
    "y = data_cleaned['Task']\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "X[numerical_cols] = numerical_imputer.fit_transform(X[numerical_cols])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_cols] = categorical_imputer.fit_transform(X[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_preprocessed = X_train_preprocessed.toarray()\n",
    "X_test_preprocessed = X_test_preprocessed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "nIzS-8mmuzMb",
    "outputId": "f7e96317-f2bc-4444-a8dd-56e72b6f1fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 11m 23s]\n",
      "val_accuracy: 0.8456768989562988\n",
      "\n",
      "Best val_accuracy So Far: 0.911896288394928\n",
      "Total elapsed time: 08h 32m 23s\n",
      "Epoch 1/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.4409 - accuracy: 0.7974 - val_loss: 0.4035 - val_accuracy: 0.8129\n",
      "Epoch 2/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.4030 - accuracy: 0.8177 - val_loss: 0.3825 - val_accuracy: 0.8261\n",
      "Epoch 3/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.3818 - accuracy: 0.8273 - val_loss: 0.3696 - val_accuracy: 0.8292\n",
      "Epoch 4/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.3628 - accuracy: 0.8364 - val_loss: 0.3555 - val_accuracy: 0.8380\n",
      "Epoch 5/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.3498 - accuracy: 0.8440 - val_loss: 0.3451 - val_accuracy: 0.8435\n",
      "Epoch 6/50\n",
      "4416/4416 [==============================] - 25s 6ms/step - loss: 0.3359 - accuracy: 0.8516 - val_loss: 0.3331 - val_accuracy: 0.8534\n",
      "Epoch 7/50\n",
      "4416/4416 [==============================] - 25s 6ms/step - loss: 0.3245 - accuracy: 0.8588 - val_loss: 0.3275 - val_accuracy: 0.8574\n",
      "Epoch 8/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.3137 - accuracy: 0.8640 - val_loss: 0.3211 - val_accuracy: 0.8600\n",
      "Epoch 9/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.3057 - accuracy: 0.8683 - val_loss: 0.3131 - val_accuracy: 0.8662\n",
      "Epoch 10/50\n",
      "4416/4416 [==============================] - 30s 7ms/step - loss: 0.2974 - accuracy: 0.8731 - val_loss: 0.3139 - val_accuracy: 0.8676\n",
      "Epoch 11/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2902 - accuracy: 0.8772 - val_loss: 0.3106 - val_accuracy: 0.8725\n",
      "Epoch 12/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.2844 - accuracy: 0.8810 - val_loss: 0.3002 - val_accuracy: 0.8763\n",
      "Epoch 13/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2773 - accuracy: 0.8836 - val_loss: 0.2981 - val_accuracy: 0.8756\n",
      "Epoch 14/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.2728 - accuracy: 0.8862 - val_loss: 0.2929 - val_accuracy: 0.8812\n",
      "Epoch 15/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.2670 - accuracy: 0.8879 - val_loss: 0.2898 - val_accuracy: 0.8816\n",
      "Epoch 16/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.2630 - accuracy: 0.8909 - val_loss: 0.3015 - val_accuracy: 0.8801\n",
      "Epoch 17/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2573 - accuracy: 0.8934 - val_loss: 0.2837 - val_accuracy: 0.8835\n",
      "Epoch 18/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2534 - accuracy: 0.8960 - val_loss: 0.2815 - val_accuracy: 0.8870\n",
      "Epoch 19/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2495 - accuracy: 0.8980 - val_loss: 0.2811 - val_accuracy: 0.8891\n",
      "Epoch 20/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2465 - accuracy: 0.8989 - val_loss: 0.2779 - val_accuracy: 0.8911\n",
      "Epoch 21/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2441 - accuracy: 0.9003 - val_loss: 0.2747 - val_accuracy: 0.8898\n",
      "Epoch 22/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2386 - accuracy: 0.9027 - val_loss: 0.2731 - val_accuracy: 0.8907\n",
      "Epoch 23/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2370 - accuracy: 0.9033 - val_loss: 0.2691 - val_accuracy: 0.8960\n",
      "Epoch 24/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.2338 - accuracy: 0.9050 - val_loss: 0.2680 - val_accuracy: 0.8961\n",
      "Epoch 25/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2300 - accuracy: 0.9068 - val_loss: 0.2700 - val_accuracy: 0.8930\n",
      "Epoch 26/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2292 - accuracy: 0.9075 - val_loss: 0.2674 - val_accuracy: 0.8967\n",
      "Epoch 27/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2246 - accuracy: 0.9100 - val_loss: 0.2611 - val_accuracy: 0.9004\n",
      "Epoch 28/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2225 - accuracy: 0.9102 - val_loss: 0.2619 - val_accuracy: 0.8993\n",
      "Epoch 29/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2215 - accuracy: 0.9112 - val_loss: 0.2631 - val_accuracy: 0.8999\n",
      "Epoch 30/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2193 - accuracy: 0.9122 - val_loss: 0.2595 - val_accuracy: 0.9015\n",
      "Epoch 31/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2165 - accuracy: 0.9129 - val_loss: 0.2649 - val_accuracy: 0.8998\n",
      "Epoch 32/50\n",
      "4416/4416 [==============================] - 30s 7ms/step - loss: 0.2156 - accuracy: 0.9134 - val_loss: 0.2632 - val_accuracy: 0.8992\n",
      "Epoch 33/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2141 - accuracy: 0.9145 - val_loss: 0.2574 - val_accuracy: 0.9037\n",
      "Epoch 34/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.2133 - accuracy: 0.9145 - val_loss: 0.2623 - val_accuracy: 0.9014\n",
      "Epoch 35/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2088 - accuracy: 0.9171 - val_loss: 0.2628 - val_accuracy: 0.9009\n",
      "Epoch 36/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2094 - accuracy: 0.9177 - val_loss: 0.2601 - val_accuracy: 0.9038\n",
      "Epoch 37/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.2068 - accuracy: 0.9182 - val_loss: 0.2589 - val_accuracy: 0.9027\n",
      "Epoch 38/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2059 - accuracy: 0.9185 - val_loss: 0.2567 - val_accuracy: 0.9042\n",
      "Epoch 39/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2027 - accuracy: 0.9197 - val_loss: 0.2549 - val_accuracy: 0.9068\n",
      "Epoch 40/50\n",
      "4416/4416 [==============================] - 29s 6ms/step - loss: 0.2025 - accuracy: 0.9197 - val_loss: 0.2555 - val_accuracy: 0.9037\n",
      "Epoch 41/50\n",
      "4416/4416 [==============================] - 26s 6ms/step - loss: 0.2020 - accuracy: 0.9202 - val_loss: 0.2574 - val_accuracy: 0.9064\n",
      "Epoch 42/50\n",
      "4416/4416 [==============================] - 28s 6ms/step - loss: 0.2016 - accuracy: 0.9206 - val_loss: 0.2594 - val_accuracy: 0.9037\n",
      "Epoch 43/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.1983 - accuracy: 0.9217 - val_loss: 0.2604 - val_accuracy: 0.9066\n",
      "Epoch 44/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.1975 - accuracy: 0.9222 - val_loss: 0.2582 - val_accuracy: 0.9054\n",
      "Epoch 45/50\n",
      "4416/4416 [==============================] - 29s 7ms/step - loss: 0.1959 - accuracy: 0.9234 - val_loss: 0.2559 - val_accuracy: 0.9075\n",
      "Epoch 46/50\n",
      "4416/4416 [==============================] - 27s 6ms/step - loss: 0.1954 - accuracy: 0.9240 - val_loss: 0.2639 - val_accuracy: 0.9077\n",
      "Epoch 47/50\n",
      "4416/4416 [==============================] - 31s 7ms/step - loss: 0.1948 - accuracy: 0.9237 - val_loss: 0.2581 - val_accuracy: 0.9089\n",
      "Epoch 48/50\n",
      "4416/4416 [==============================] - 31s 7ms/step - loss: 0.1930 - accuracy: 0.9245 - val_loss: 0.2667 - val_accuracy: 0.9078\n",
      "Epoch 49/50\n",
      "4416/4416 [==============================] - 33s 7ms/step - loss: 0.1911 - accuracy: 0.9251 - val_loss: 0.2502 - val_accuracy: 0.9087\n",
      "Epoch 50/50\n",
      "4416/4416 [==============================] - 38s 9ms/step - loss: 0.1916 - accuracy: 0.9249 - val_loss: 0.2486 - val_accuracy: 0.9110\n",
      "Best Hyperparameters:\n",
      "{'layers': 4, 'units_0': 256, 'dropout_0': 0.2, 'units_1': 192, 'dropout_1': 0.2, 'units_2': 256, 'dropout_2': 0.2, 'units_3': 32, 'dropout_3': 0.4, 'units_4': 160, 'dropout_4': 0.2}\n",
      "\n",
      "Architecture of the Best Model:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               30464     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 192)               49344     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               49408     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,473\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "#     hp_units = hp.Int('units', min_value=32, max_value=256, step=32)\n",
    "#     model.add(layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "#     hp_dropout = hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
    "#     model.add(layers.Dropout(rate=hp_dropout))\n",
    "    \n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# X_train_dense = X_train.todense()\n",
    "# X_val_dense = X_val.todense()\n",
    "\n",
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     model.add(layers.InputLayer(input_shape=(X_train_dense.shape[1],)))\n",
    "\n",
    "#     hp_layers = hp.Int('layers', min_value=1, max_value=5, step=1)\n",
    "    \n",
    "#     for i in range(hp_layers):\n",
    "#         units = hp.Int(f'units_{i}', min_value=32, max_value=256, step=32)\n",
    "#         model.add(layers.Dense(units=units, activation='relu'))\n",
    "        \n",
    "#         dropout = hp.Float(f'dropout_{i}', min_value=0.2, max_value=0.5, step=0.1)\n",
    "#         model.add(layers.Dropout(rate=dropout))\n",
    "\n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# tuner = kt.RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_trials=50,  # Adjust as needed for a longer search\n",
    "#     directory='new',  # Specify a directory to store the tuning results\n",
    "#     project_name='my_tuning_project'\n",
    "# )\n",
    "\n",
    "# tuner.search(X_train_dense, y_train, epochs=50, validation_data=(X_val_dense, y_val))\n",
    "\n",
    "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# best_model.fit(X_train_dense, y_train, epochs=50, validation_data=(X_val_dense, y_val))\n",
    "\n",
    "# print(\"Best Hyperparameters:\")\n",
    "# print(best_hps.values)\n",
    "\n",
    "# print(\"\\nArchitecture of the Best Model:\")\n",
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 256)               30464     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 192)               49344     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               49408     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                8224      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,473\n",
      "Trainable params: 137,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x0000026D66317400>\n"
     ]
    }
   ],
   "source": [
    "# print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(X_train_preprocessed.shape[1],)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(192, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(160, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_preprocessed,\n",
    "    y_train,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test_preprocessed, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "\n",
    "new_data['Year'] = new_data['Date'].dt.year\n",
    "new_data['Month'] = new_data['Date'].dt.month\n",
    "new_data['Day'] = new_data['Date'].dt.day\n",
    "\n",
    "new_data.drop(['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = new_data[\"ID\"]\n",
    "new_data.drop(\"ID\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = new_data.select_dtypes(exclude=['object']).columns\n",
    "categorical_cols = new_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "new_data[numerical_cols] = numerical_imputer.fit_transform(new_data[numerical_cols])\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "new_data[categorical_cols] = categorical_imputer.fit_transform(new_data[categorical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = new_data\n",
    "X_new_preprocessed = preprocessor.transform(X_new)\n",
    "X_new_preprocessed = X_new_preprocessed.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_new_preprocessed)\n",
    "rounded_predictions = np.round(predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
